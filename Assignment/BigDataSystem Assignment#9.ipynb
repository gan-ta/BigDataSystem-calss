{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+----------+---------+------+-------------------+-----------+------+\n",
      "|     id|firstName|middleName| lastName|gender|          birthDate|        ssn|salary|\n",
      "+-------+---------+----------+---------+------+-------------------+-----------+------+\n",
      "|8807768|   Darren|      Minh|Pilsworth|     M|1967-03-07 14:00:00|908-34-1027| 45983|\n",
      "|8807769|  Winston|     Hiram|    Ahlin|     M|1957-07-10 13:30:00|946-32-4802| 45867|\n",
      "|8807770|   Arnold|     Jason|   Durran|     M|1987-10-18 13:00:00|978-34-4842| 58623|\n",
      "|8807771|    Garth|      Dino|   Eddins|     M|1998-07-16 13:00:00|992-39-5689| 33952|\n",
      "|8807772|Sebastian|      Levi|    Evans|     M|1958-01-23 13:30:00|963-59-2493| 31453|\n",
      "+-------+---------+----------+---------+------+-------------------+-----------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "peopleDF = spark.read.parquet(\"people-10m.parquet\")\n",
    "peopleDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['firstName', 'middleName', 'lastName']\n",
      "+---------+----------+---------+\n",
      "|firstName|middleName| lastName|\n",
      "+---------+----------+---------+\n",
      "|   Darren|      Minh|Pilsworth|\n",
      "+---------+----------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "+----------+-----+\n",
      "|middleName|count|\n",
      "+----------+-----+\n",
      "|   Rosendo| 3956|\n",
      "|   Normand| 4100|\n",
      "|  Laurence| 3960|\n",
      "|     Tyler| 3999|\n",
      "|      Reta| 1277|\n",
      "+----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "name_list = [c for c in peopleDF.columns if 'Name' in c]\n",
    "print(name_list)\n",
    "nameDF = peopleDF[name_list]\n",
    "nameDF.show(1)\n",
    "\n",
    "nameDF.groupBy('middleName').count().show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5113\n",
      "+---------+\n",
      "|firstName|\n",
      "+---------+\n",
      "|    Zulma|\n",
      "|   Zulema|\n",
      "|     Zula|\n",
      "|  Zoraida|\n",
      "|     Zora|\n",
      "+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "firstName = peopleDF.select('firstName').distinct()\n",
    "print(firstName.count())\n",
    "sortingDF = firstName.orderBy(\"firstName\",ascending=False)\n",
    "sortingDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----+\n",
      "|firstName|birthYear|count|\n",
      "+---------+---------+-----+\n",
      "|  Dorothy|     1954|   29|\n",
      "|    Donna|     1985|   27|\n",
      "|    Donna|     1974|   20|\n",
      "|  Dorothy|     1984|   27|\n",
      "|    Donna|     1968|   27|\n",
      "+---------+---------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import year,col\n",
    "dordonDF = peopleDF.\\\n",
    "            select(year('birthDate').alias(\"birthYear\"),\"firstName\").\\\n",
    "            filter((col(\"firstName\") == \"Donna\") | (col(\"firstName\") == \"Dorothy\")).\\\n",
    "            filter(\"gender == 'F'\").\\\n",
    "            orderBy('birthYear').\\\n",
    "            groupBy('firstName','birthYear').\\\n",
    "            count().show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dordonDF = peopleDF.\\\n",
    "            select(year('birthDate').alias(\"birthYear\"),\"firstName\").\\\n",
    "            filter((col(\"firstName\") == \"Donna\") | (col(\"firstName\") == \"Dorothy\")).\\\n",
    "            filter(\"gender == 'F'\").\\\n",
    "            filter(year(\"birthDate\") > \"1990\").\\\n",
    "            orderBy('birthYear').\\\n",
    "            groupBy('firstName','birthYear').\\\n",
    "            count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[firstName: string, birthYear: int, count: bigint]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----+\n",
      "|firstName|birthYear|count|\n",
      "+---------+---------+-----+\n",
      "|    Donna|     1996|   23|\n",
      "|    Donna|     1998|   28|\n",
      "|    Donna|     2000|    2|\n",
      "|  Dorothy|     1992|   39|\n",
      "|    Donna|     1991|   27|\n",
      "|    Donna|     1999|   22|\n",
      "|  Dorothy|     1998|   33|\n",
      "|  Dorothy|     1996|   19|\n",
      "|  Dorothy|     1993|   28|\n",
      "|  Dorothy|     1994|   21|\n",
      "|  Dorothy|     1995|   26|\n",
      "|  Dorothy|     1999|   25|\n",
      "|  Dorothy|     2000|    4|\n",
      "|    Donna|     1997|   36|\n",
      "|    Donna|     1994|   26|\n",
      "|  Dorothy|     1991|   25|\n",
      "|    Donna|     1995|   33|\n",
      "|    Donna|     1992|   30|\n",
      "|  Dorothy|     1997|   24|\n",
      "|    Donna|     1993|   22|\n",
      "+---------+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display(dordonDF)\n",
    "dordonDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+----+-------------+\n",
      "|name|math score|name|english score|\n",
      "+----+----------+----+-------------+\n",
      "| jun|        75| jun|           67|\n",
      "| tom|        70| tom|           55|\n",
      "| sam|        60| sam|           88|\n",
      "+----+----------+----+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mathS_df = spark.createDataFrame([('tom',70),('bob',100),('sam',60),('lee',85),('jun',75)],['name','score'])\n",
    "englishS_df = spark.createDataFrame([('tom',55),('sam',88),('kim',90),('jun',67),('choi',95)],['name','score'])\n",
    "\n",
    "\n",
    "mathS_df = mathS_df.select('name',col('score').alias('math score'))\n",
    "englishS_df = englishS_df.select('name',col('score').alias('english score'))\n",
    "\n",
    "\n",
    "join1 = mathS_df.join(englishS_df, mathS_df.name == englishS_df.name)\n",
    "join1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+----+-------------+\n",
      "|name|math score|name|english score|\n",
      "+----+----------+----+-------------+\n",
      "|null|      null|choi|           95|\n",
      "|null|      null| kim|           90|\n",
      "+----+----------+----+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mathS_df = spark.createDataFrame([('tom',70),('bob',100),('sam',60),('lee',85),('jun',75)],['name','score'])\n",
    "englishS_df = spark.createDataFrame([('tom',55),('sam',88),('kim',90),('jun',67),('choi',95)],['name','score'])\n",
    "\n",
    "\n",
    "mathS_df = mathS_df.select('name',col('score').alias('math score'))\n",
    "englishS_df = englishS_df.select('name',col('score').alias('english score'))\n",
    "\n",
    "join2 = mathS_df.join(englishS_df, mathS_df.name == englishS_df.name,how='full').\\\n",
    "                filter(mathS_df.name.isNull())\n",
    "    \n",
    "join2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+----------+---------+------+-------------------+-----------+------+\n",
      "|     id|firstName|middleName| lastName|gender|          birthDate|        ssn|salary|\n",
      "+-------+---------+----------+---------+------+-------------------+-----------+------+\n",
      "|8807768|   Darren|      Minh|Pilsworth|     M|1967-03-07 14:00:00|908-34-1027| 45983|\n",
      "|8807769|  Winston|     Hiram|    Ahlin|     M|1957-07-10 13:30:00|946-32-4802| 45867|\n",
      "|8807770|   Arnold|     Jason|   Durran|     M|1987-10-18 13:00:00|978-34-4842| 58623|\n",
      "|8807771|    Garth|      Dino|   Eddins|     M|1998-07-16 13:00:00|992-39-5689| 33952|\n",
      "|8807772|Sebastian|      Levi|    Evans|     M|1958-01-23 13:30:00|963-59-2493| 31453|\n",
      "+-------+---------+----------+---------+------+-------------------+-----------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "peopleDF = spark.read.parquet(\"people-10m.parquet\")\n",
    "peopleDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|firstName|total|\n",
      "+---------+-----+\n",
      "|  Marcelo| 4197|\n",
      "| Reynaldo| 4193|\n",
      "|  Jeffrey| 4177|\n",
      "|   Sammie| 4170|\n",
      "|     Troy| 4167|\n",
      "+---------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as fn\n",
    "top10MaleFirstNameDF = peopleDF.\\\n",
    "                        select(\"firstName\").\\\n",
    "                        filter(\"gender = 'M'\").\\\n",
    "                        groupBy(\"firstName\").\\\n",
    "                        agg(fn.count(\"firstName\").alias('total')).\\\n",
    "                        orderBy(\"total\",ascending = False).\\\n",
    "                        limit(10)\n",
    "\n",
    "top10MaleFirstNameDF.show(5)\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[firstName: string, total: bigint]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|firstName|total|\n",
      "+---------+-----+\n",
      "|    Darin| 4166|\n",
      "|    Fritz| 4157|\n",
      "|  Jeffrey| 4177|\n",
      "|     Jess| 4153|\n",
      "|  Marcelo| 4197|\n",
      "| Reynaldo| 4193|\n",
      "|   Sammie| 4170|\n",
      "|    Tomas| 4161|\n",
      "|     Troy| 4167|\n",
      "|    Wyatt| 4159|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top10MaleFirstNameDF.createOrReplaceTempView(\"top10MaleFirstName\")\n",
    "resultDF = spark.sql(\"select * from top10MaleFirstName order by firstname\")\n",
    "display(resultDF)\n",
    "resultDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
